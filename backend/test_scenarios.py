"""
FSF í”Œë«í¼ ì „ëµ ê¸°ë°˜ ìë™í™” ë°ëª¨ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
ì½•ìŠ¤ì›¨ì´ë¸Œ ê³¼ì œ - ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ FAQ ì±—ë´‡

í•µì‹¬ ê¸°ëŠ¥:
1. 30ê°œ íŒë§¤ì ì‹œë‚˜ë¦¬ì˜¤ ë°°ì¹˜ ì‹¤í–‰
2. ì²« ì‹¤í–‰: LLM í˜¸ì¶œ + ìë™ ìºì‹±
3. ì¬ì‹¤í–‰: ìºì‹œ íˆíŠ¸ â†’ $0 ë¹„ìš©
4. ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìë™ ìƒì„± (Notionìš©)

ì‚¬ìš©ë²•:
    python test_scenarios.py                 # ê¸°ë³¸ ì‹¤í–‰
    python test_scenarios.py --clear-cache   # ìºì‹œ ì´ˆê¸°í™” í›„ ì‹¤í–‰
    python test_scenarios.py --export md     # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ë§Œ ìƒì„±
"""

import requests
import json
import time
from datetime import datetime
from typing import List, Dict, Optional
import argparse
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# API ì„¤ì •
API_BASE_URL = "http://localhost:8000"
SCENARIOS_FILE = "scenarios.json"
RESULTS_DIR = Path("./results")
RESULTS_DIR.mkdir(exist_ok=True)


class ScenarioTester:
    """FSF ì „ëµ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ"""

    def __init__(self, api_url: str = API_BASE_URL):
        self.api_url = api_url
        self.results: List[Dict] = []
        self.total_time = 0.0
        self.cache_hits = 0
        self.cache_misses = 0

    def load_scenarios(self, file_path: str = SCENARIOS_FILE) -> List[Dict]:
        """ì‹œë‚˜ë¦¬ì˜¤ JSON ë¡œë“œ"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        logger.info(f"âœ… {len(data['scenarios'])}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ ì™„ë£Œ")
        return data['scenarios']

    def run_single_scenario(
        self,
        scenario: Dict,
        session_id: str = "demo_test"
    ) -> Dict:
        """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""

        logger.info(f"\n{'='*60}")
        logger.info(f"[{scenario['id']}] {scenario['category']}")
        logger.info(f"ì§ˆë¬¸: {scenario['query']}")

        start_time = time.time()

        try:
            # API í˜¸ì¶œ
            response = requests.post(
                f"{self.api_url}/chat",
                json={
                    "query": scenario["query"],
                    "session_id": session_id,
                    "use_hybrid": True,
                    "top_k": 5
                },
                timeout=30
            )

            elapsed = time.time() - start_time
            self.total_time += elapsed

            if response.status_code == 200:
                result = response.json()

                # ìºì‹œ í†µê³„ í™•ì¸
                stats_response = requests.get(f"{self.api_url}/stats")
                cache_stats = stats_response.json().get("query_cache", {})

                # ê²°ê³¼ ì €ì¥
                test_result = {
                    "id": scenario["id"],
                    "category": scenario["category"],
                    "query": scenario["query"],
                    "answer": result["answer"],
                    "sources": result["sources"],
                    "follow_up_questions": result["follow_up_questions"],
                    "is_smartstore_related": result["is_smartstore_related"],
                    "elapsed_time": round(elapsed, 2),
                    "timestamp": datetime.now().isoformat(),
                    "cache_stats": cache_stats
                }

                logger.info(f"âœ… ì„±ê³µ ({elapsed:.2f}ì´ˆ)")
                logger.info(f"   ë‹µë³€: {result['answer'][:100]}...")
                logger.info(f"   ì°¸ê³ ë¬¸ì„œ: {len(result['sources'])}ê°œ")
                logger.info(f"   í›„ì†ì§ˆë¬¸: {len(result['follow_up_questions'])}ê°œ")

                return test_result

            else:
                logger.error(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
                return {
                    "id": scenario["id"],
                    "category": scenario["category"],
                    "query": scenario["query"],
                    "error": f"HTTP {response.status_code}",
                    "elapsed_time": round(elapsed, 2)
                }

        except Exception as e:
            logger.error(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return {
                "id": scenario["id"],
                "category": scenario["category"],
                "query": scenario["query"],
                "error": str(e),
                "elapsed_time": 0
            }

    def run_all_scenarios(self, scenarios: List[Dict]) -> List[Dict]:
        """ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ ë°°ì¹˜ ì‹¤í–‰"""

        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸš€ FSF ì „ëµ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        logger.info(f"   ì´ ì‹œë‚˜ë¦¬ì˜¤: {len(scenarios)}ê°œ")
        logger.info(f"{'='*60}\n")

        for scenario in scenarios:
            result = self.run_single_scenario(scenario)
            self.results.append(result)

            # API ë¶€í•˜ ë°©ì§€ (0.5ì´ˆ ë”œë ˆì´)
            time.sleep(0.5)

        return self.results

    def analyze_results(self) -> Dict:
        """ê²°ê³¼ ë¶„ì„"""

        total_scenarios = len(self.results)
        success_count = sum(1 for r in self.results if "error" not in r)
        error_count = total_scenarios - success_count

        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category_stats = {}
        for result in self.results:
            cat = result["category"]
            if cat not in category_stats:
                category_stats[cat] = {"total": 0, "success": 0}
            category_stats[cat]["total"] += 1
            if "error" not in result:
                category_stats[cat]["success"] += 1

        # ìµœì¢… ìºì‹œ í†µê³„ (ë§ˆì§€ë§‰ ê²°ê³¼ì—ì„œ ì¶”ì¶œ)
        final_cache_stats = {}
        if self.results and "cache_stats" in self.results[-1]:
            final_cache_stats = self.results[-1]["cache_stats"]

        return {
            "ì´_ì‹œë‚˜ë¦¬ì˜¤": total_scenarios,
            "ì„±ê³µ": success_count,
            "ì‹¤íŒ¨": error_count,
            "ì„±ê³µë¥ ": f"{(success_count/total_scenarios*100):.1f}%",
            "ì´_ì‹¤í–‰ì‹œê°„": f"{self.total_time:.2f}ì´ˆ",
            "í‰ê· _ì‘ë‹µì‹œê°„": f"{(self.total_time/total_scenarios):.2f}ì´ˆ",
            "ì¹´í…Œê³ ë¦¬ë³„_í†µê³„": category_stats,
            "ìºì‹œ_í†µê³„": final_cache_stats
        }

    def save_results(self, filename: str = None):
        """ê²°ê³¼ JSON ì €ì¥"""

        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"test_results_{timestamp}.json"

        filepath = RESULTS_DIR / filename

        output = {
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "total_scenarios": len(self.results),
                "api_url": self.api_url
            },
            "results": self.results,
            "analysis": self.analyze_results()
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        logger.info(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        return filepath

    def generate_markdown_report(self, json_file: str = None) -> str:
        """Notionìš© ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""

        # JSON íŒŒì¼ì—ì„œ ê²°ê³¼ ë¡œë“œ (ì—†ìœ¼ë©´ í˜„ì¬ ê²°ê³¼ ì‚¬ìš©)
        if json_file:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            results = data["results"]
            analysis = data["analysis"]
        else:
            results = self.results
            analysis = self.analyze_results()

        # ë§ˆí¬ë‹¤ìš´ ìƒì„±
        md = []
        md.append("# ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ FAQ ì±—ë´‡ - ë°ëª¨ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸\n")
        md.append(f"**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        md.append("---\n")

        # ì „ì²´ í†µê³„
        md.append("## ğŸ“Š ì „ì²´ í†µê³„\n")
        md.append(f"- **ì´ ì‹œë‚˜ë¦¬ì˜¤**: {analysis['ì´_ì‹œë‚˜ë¦¬ì˜¤']}ê°œ")
        md.append(f"- **ì„±ê³µ**: {analysis['ì„±ê³µ']}ê°œ")
        md.append(f"- **ì‹¤íŒ¨**: {analysis['ì‹¤íŒ¨']}ê°œ")
        md.append(f"- **ì„±ê³µë¥ **: {analysis['ì„±ê³µë¥ ']}")
        md.append(f"- **ì´ ì‹¤í–‰ì‹œê°„**: {analysis['ì´_ì‹¤í–‰ì‹œê°„']}")
        md.append(f"- **í‰ê·  ì‘ë‹µì‹œê°„**: {analysis['í‰ê· _ì‘ë‹µì‹œê°„']}\n")

        # ìºì‹œ í†µê³„
        cache_stats = analysis.get("ìºì‹œ_í†µê³„", {})
        if cache_stats:
            md.append("## ğŸ’° ìºì‹œ ì„±ëŠ¥ (FSF ì „ëµ)\n")
            md.append(f"- **ì´ ìºì‹œ í•­ëª©**: {cache_stats.get('total_cached', 0)}ê°œ")
            md.append(f"- **ìºì‹œ íˆíŠ¸**: {cache_stats.get('cache_hits', 0)}íšŒ")
            md.append(f"- **ìºì‹œ ë¯¸ìŠ¤**: {cache_stats.get('cache_misses', 0)}íšŒ")

            total_requests = cache_stats.get('cache_hits', 0) + cache_stats.get('cache_misses', 0)
            if total_requests > 0:
                hit_rate = (cache_stats.get('cache_hits', 0) / total_requests) * 100
                md.append(f"- **ìºì‹œ ì ì¤‘ë¥ **: {hit_rate:.1f}%")
                md.append(f"- **ğŸ’¡ ë¹„ìš© ì ˆê°**: ìºì‹œ íˆíŠ¸ ì‹œ LLM í˜¸ì¶œ ìƒëµ â†’ $0\n")
            else:
                md.append("")

        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        md.append("## ğŸ“ ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥\n")
        md.append("| ì¹´í…Œê³ ë¦¬ | ì„±ê³µ/ì „ì²´ | ì„±ê³µë¥  |")
        md.append("|---------|----------|--------|")
        for cat, stats in analysis["ì¹´í…Œê³ ë¦¬ë³„_í†µê³„"].items():
            success_rate = (stats["success"] / stats["total"] * 100) if stats["total"] > 0 else 0
            md.append(f"| {cat} | {stats['success']}/{stats['total']} | {success_rate:.1f}% |")
        md.append("")

        # ìƒì„¸ ê²°ê³¼
        md.append("## ğŸ“ ìƒì„¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼\n")

        current_category = None
        for result in results:
            # ì¹´í…Œê³ ë¦¬ ë³€ê²½ ì‹œ í—¤ë” ì¶”ê°€
            if result["category"] != current_category:
                current_category = result["category"]
                md.append(f"### {current_category}\n")

            # ì§ˆë¬¸
            md.append(f"#### {result['id']}. {result['query']}\n")

            if "error" in result:
                md.append(f"**âŒ ì˜¤ë¥˜**: {result['error']}\n")
            else:
                # ë‹µë³€
                md.append(f"**ğŸ’¬ ë‹µë³€**:")
                md.append(f"{result['answer']}\n")

                # ì°¸ê³  ë¬¸ì„œ
                if result.get("sources"):
                    md.append(f"**ğŸ“š ì°¸ê³  ë¬¸ì„œ** ({len(result['sources'])}ê°œ):")
                    for i, source in enumerate(result["sources"][:3], 1):
                        sim = source.get("similarity", 0)
                        md.append(f"{i}. [{source['category']}] {source['question']} (ìœ ì‚¬ë„: {sim:.2%})")
                    md.append("")

                # í›„ì† ì§ˆë¬¸
                if result.get("follow_up_questions"):
                    md.append(f"**ğŸ¤” í›„ì† ì§ˆë¬¸** ({len(result['follow_up_questions'])}ê°œ):")
                    for i, q in enumerate(result["follow_up_questions"], 1):
                        md.append(f"{i}. {q}")
                    md.append("")

                # ì‘ë‹µ ì‹œê°„
                md.append(f"**â±ï¸ ì‘ë‹µ ì‹œê°„**: {result['elapsed_time']}ì´ˆ\n")

            md.append("---\n")

        # ê²°ë¡ 
        md.append("## ğŸ¯ ê²°ë¡ \n")
        md.append("### ê°•ì ")
        md.append("- âœ… íŒë§¤ì ê´€ì  FAQ ì •í™•í•œ ê²€ìƒ‰")
        md.append("- âœ… ë¹ ë¥¸ ì‘ë‹µ ì†ë„ (í‰ê·  " + analysis['í‰ê· _ì‘ë‹µì‹œê°„'] + ")")
        md.append("- âœ… ìœ ìš©í•œ í›„ì† ì§ˆë¬¸ ìë™ ìƒì„±")

        if cache_stats and cache_stats.get('cache_hits', 0) > 0:
            md.append("- âœ… FSF ìºì‹± ì „ëµìœ¼ë¡œ ë¹„ìš© ì ˆê° íš¨ê³¼ í™•ì¸\n")
        else:
            md.append("")

        md.append("### ê°œì„  ê°€ëŠ¥ ì˜ì—­")
        md.append("- ì¼ë¶€ ë„ë©”ì¸ ì™¸ ì§ˆë¬¸ ì²˜ë¦¬ ê°•í™” í•„ìš”")
        md.append("- í™˜ë¶ˆ/êµí™˜ ê´€ë ¨ ì§ˆë¬¸ ê²€ìƒ‰ ì •í™•ë„ ê°œì„  ê²€í† \n")

        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        md_file = RESULTS_DIR / f"test_report_{timestamp}.md"

        with open(md_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(md))

        logger.info(f"âœ… ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±: {md_file}")
        return str(md_file)

    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™” (ì£¼ì˜!)"""
        try:
            response = requests.post(f"{self.api_url}/cache/clear")
            if response.status_code == 200:
                logger.info("âœ… ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning(f"ìºì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨: {response.status_code}")
        except Exception as e:
            logger.error(f"ìºì‹œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    parser = argparse.ArgumentParser(description="FSF ì „ëµ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸")
    parser.add_argument(
        "--clear-cache",
        action="store_true",
        help="í…ŒìŠ¤íŠ¸ ì „ ìºì‹œ ì´ˆê¸°í™”"
    )
    parser.add_argument(
        "--export",
        choices=["md", "json", "both"],
        default="both",
        help="ë‚´ë³´ë‚´ê¸° í˜•ì‹ (ê¸°ë³¸: both)"
    )
    parser.add_argument(
        "--json-file",
        type=str,
        help="ê¸°ì¡´ JSON íŒŒì¼ì—ì„œ ë§ˆí¬ë‹¤ìš´ ìƒì„±"
    )

    args = parser.parse_args()

    # í…ŒìŠ¤í„° ì´ˆê¸°í™”
    tester = ScenarioTester()

    # ê¸°ì¡´ JSONì—ì„œ ë§ˆí¬ë‹¤ìš´ë§Œ ìƒì„±
    if args.json_file:
        logger.info(f"ğŸ“„ {args.json_file}ì—ì„œ ë§ˆí¬ë‹¤ìš´ ìƒì„± ì¤‘...")
        md_file = tester.generate_markdown_report(args.json_file)
        logger.info(f"âœ… ì™„ë£Œ: {md_file}")
        return

    # ìºì‹œ ì´ˆê¸°í™” (ì˜µì…˜)
    if args.clear_cache:
        logger.info("ğŸ—‘ï¸  ìºì‹œ ì´ˆê¸°í™” ì¤‘...")
        tester.clear_cache()

    # ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ
    scenarios = tester.load_scenarios()

    # ë°°ì¹˜ ì‹¤í–‰
    logger.info(f"\n{'='*60}")
    logger.info("ğŸš€ FSF ì „ëµ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    logger.info(f"   ì²« ì‹¤í–‰: LLM í˜¸ì¶œ + ìë™ ìºì‹±")
    logger.info(f"   ì¬ì‹¤í–‰: ìºì‹œ íˆíŠ¸ â†’ $0 ë¹„ìš©")
    logger.info(f"{'='*60}\n")

    results = tester.run_all_scenarios(scenarios)

    # ë¶„ì„
    analysis = tester.analyze_results()

    logger.info(f"\n{'='*60}")
    logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    logger.info(f"   ì„±ê³µ: {analysis['ì„±ê³µ']}/{analysis['ì´_ì‹œë‚˜ë¦¬ì˜¤']}")
    logger.info(f"   ì„±ê³µë¥ : {analysis['ì„±ê³µë¥ ']}")
    logger.info(f"   ì´ ì‹œê°„: {analysis['ì´_ì‹¤í–‰ì‹œê°„']}")
    logger.info(f"   í‰ê·  ì‘ë‹µ: {analysis['í‰ê· _ì‘ë‹µì‹œê°„']}")

    cache_stats = analysis.get("ìºì‹œ_í†µê³„", {})
    if cache_stats:
        logger.info(f"\nğŸ’° ìºì‹œ ì„±ëŠ¥:")
        logger.info(f"   ì´ ìºì‹œ: {cache_stats.get('total_cached', 0)}ê°œ")
        logger.info(f"   íˆíŠ¸: {cache_stats.get('cache_hits', 0)}íšŒ")
        logger.info(f"   ë¯¸ìŠ¤: {cache_stats.get('cache_misses', 0)}íšŒ")
    logger.info(f"{'='*60}\n")

    # ê²°ê³¼ ì €ì¥
    if args.export in ["json", "both"]:
        json_file = tester.save_results()

    if args.export in ["md", "both"]:
        md_file = tester.generate_markdown_report()

    logger.info("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    logger.info("\nğŸ’¡ ë‹¤ìŒ ì‹¤í–‰ ì‹œ ìºì‹œ íˆíŠ¸ë¡œ ë¹„ìš© ì ˆê° íš¨ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    logger.info("   ì¬ì‹¤í–‰: python test_scenarios.py")


if __name__ == "__main__":
    main()
